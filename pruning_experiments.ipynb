{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from yolov5.utils.general import (check_dataset, check_img_size, non_max_suppression, scale_coords, xyxy2xywh)\n",
    "from yolov5.utils.metrics import ap_per_class\n",
    "from yolov5.utils.dataloaders import create_dataloader\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(model, amount=0.3):\n",
    "    import torch.nn.utils.prune as prune\n",
    "    print('Pruning model... ', end='')\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(m, name='weight', amount=amount)  # prune\n",
    "            prune.remove(m, 'weight')  # make permanent\n",
    "    print(' %.3g global sparsity' % sparsity(model))\n",
    "    return model\n",
    "            \n",
    "def sparsity(model):\n",
    "    # Return global model sparsity\n",
    "    a, b = 0, 0\n",
    "    for p in model.parameters():\n",
    "        a += p.numel()\n",
    "        b += (p == 0).sum()\n",
    "    return b / a\n",
    "\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "\n",
    "def flops_and_params(model):\n",
    "    example_inputs = torch.randn(1, 3, 640, 640).to(device)\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    flops = 2 * macs\n",
    "    return flops, nparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_yaml, device='cuda:0', img_size=640, batch_size=32, conf_thres=0.001, iou_thres=0.6):\n",
    "    \"\"\"\n",
    "    YOLOv5 모델 테스트 함수 (2022년 초 버전 기반).\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): PyTorch YOLOv5 모델 객체\n",
    "        data_yaml (str or Path): 데이터셋 yaml 파일 경로\n",
    "        device (str): 'cuda' 또는 'cpu'\n",
    "        img_size (int): 입력 이미지 크기 (정사각형 기준)\n",
    "        batch_size (int): 배치 크기\n",
    "        conf_thres (float): Confidence threshold\n",
    "        iou_thres (float): IoU threshold for NMS\n",
    "    \n",
    "    Returns:\n",
    "        dict: 테스트 결과 메트릭 (Precision, Recall, mAP@0.5, mAP@0.5:0.95)\n",
    "    \"\"\"\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = torch.device(device)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # 데이터셋 확인\n",
    "    data = check_dataset(data_yaml)\n",
    "    names = data['names']\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    stride = int(model.stride.max())\n",
    "    img_size = check_img_size(img_size, s=stride)\n",
    "    _, dataloader, _ = create_dataloader(\n",
    "        path=data['val'],\n",
    "        imgsz=img_size,\n",
    "        batch_size=batch_size,\n",
    "        stride=stride,\n",
    "        pad=0.5,\n",
    "        rect=True,\n",
    "        workers=4,\n",
    "        prefix='val: '\n",
    "    )\n",
    "\n",
    "    # 테스트 루프\n",
    "    stats, ap, ap_class = [], [], []\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=\"Testing\")):\n",
    "        img = img.to(device, non_blocking=True).float() / 255.0  # 정규화\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # 추론\n",
    "        with torch.no_grad():\n",
    "            pred = model(img)\n",
    "            pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False)\n",
    "\n",
    "        # 메트릭 계산\n",
    "        for si, pred_i in enumerate(pred):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "            tcls = labels[:, 0].tolist() if nl else []\n",
    "            correct = torch.zeros(pred_i.shape[0], nl, dtype=torch.bool, device=device)\n",
    "\n",
    "            if len(pred_i):\n",
    "                predn = pred_i.clone()\n",
    "                scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0])  # 스케일 조정\n",
    "                for ci, p in enumerate(predn):\n",
    "                    ious = box_iou(p[None, :4], labels[:, 1:5]) > iou_thres\n",
    "                    correct[ci, :] = ious\n",
    "\n",
    "            stats.append((correct.cpu(), pred_i[:, 4].cpu(), pred_i[:, 5].cpu(), tcls))\n",
    "\n",
    "    # AP 계산\n",
    "    stats = [torch.cat(x, 0).numpy() for x in zip(*stats)]  # stats 압축\n",
    "    p, r, ap, f1, ap_class = ap_per_class(*stats, plot=False)\n",
    "    mp, mr, map50, map95 = p.mean(), r.mean(), ap[:, 0].mean(), ap.mean()  # 평균 계산\n",
    "\n",
    "    # 결과 반환\n",
    "    results = {\n",
    "        'Precision': mp,\n",
    "        'Recall': mr,\n",
    "        'mAP@0.5': map50,\n",
    "        'mAP@0.5:0.95': map95\n",
    "    }\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "# Example Usage (adjust paths as needed):\n",
    "# test_yolov5_v1(model, data_yaml='data/coco128.yaml', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pruning_ratios = np.linspace(0.0, 0.5, 6)  # 0%, 10%, ..., 50%\n",
    "results = []\n",
    "\n",
    "model = torch.hub.load('yolov5', 'custom', 'finetuned_weights/yolov5n_finetuned.pt', source='local', force_reload=True, device=device)\n",
    "\n",
    "for ratio in pruning_ratios:\n",
    "    print(ratio)\n",
    "    pruned_model = prune(model, pruning_ratio=ratio)\n",
    "    metrics = evaluate(model=model, data_yaml='./yolov5/data/glasses.yaml')\n",
    "    results.append([ratio, metrics['Precision'], metrics['Recall'], metrics['mAP@0.5'], metrics['mAP@0.5:0.95']])\n",
    "    print('{} complete'.format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 추출\n",
    "ratios = [r[0] for r in results]\n",
    "precision_score = [r[1] for r in results]\n",
    "recall_score = [r[2] for r in results]\n",
    "map50_scores = [r[3] for r in results]\n",
    "map50_95_scores = [r[4] for r in results]\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ratios, precision_score, marker='o', label='precision')\n",
    "plt.plot(ratios, recall_score, marker='o', label='recall')\n",
    "plt.plot(ratios, map50_scores, marker='o', label='mAP@0.5')\n",
    "plt.plot(ratios, map50_95_scores, marker='s', label='mAP@0.5:0.95')\n",
    "\n",
    "plt.title(\"YOLOv5 Pruning Ratio vs Performance\")\n",
    "plt.xlabel(\"Pruning Ratio\")\n",
    "plt.ylabel(\"Performance (mAP)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
