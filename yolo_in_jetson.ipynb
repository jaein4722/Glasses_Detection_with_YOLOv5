{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041a67d-27ea-4d7b-8993-7cbafaf4dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af6923-aac7-4754-b48f-3cbc618e8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gstreamer_pipeline(\n",
    "    sensor_id=0,\n",
    "    capture_width=1280,\n",
    "    capture_height=720,\n",
    "    display_width=1280,\n",
    "    display_height=720,\n",
    "    framerate=60,\n",
    "    flip_method=0,\n",
    "):\n",
    "    return (\n",
    "        \"nvarguscamerasrc sensor-id=%d ! \"\n",
    "        \"video/x-raw(memory:NVMM), width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "        \"nvvidconv flip-method=%d ! \"\n",
    "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
    "        \"videoconvert ! \"\n",
    "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "        % (\n",
    "            sensor_id,\n",
    "            capture_width,\n",
    "            capture_height,\n",
    "            framerate,\n",
    "            flip_method,\n",
    "            display_width,\n",
    "            display_height,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c95353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(model):\n",
    "    COLORS = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255)]  # 다양한 색상\n",
    "    window_title = \"YOLOv5 detection\"\n",
    "\n",
    "    # To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "    print(gstreamer_pipeline(flip_method=0))\n",
    "    video_capture = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "    if video_capture.isOpened():\n",
    "        try:\n",
    "            window_handle = cv2.namedWindow(window_title, cv2.WINDOW_AUTOSIZE)\n",
    "            while True:\n",
    "                ret_val, frame = video_capture.read()\n",
    "                if not ret_val:\n",
    "                    break\n",
    "                results = model(frame, size=1280, augment=True)\n",
    "                \n",
    "                for *xyxy, conf, cls in results.xyxy[0].tolist():\n",
    "                    x1, y1, x2, y2 = map(int, xyxy)\n",
    "                    label = f\"{results.names[int(cls)]} {conf:.2f}\"\n",
    "                    color = COLORS[int(cls) % len(COLORS)]\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                    label_x1, label_y1 = x1, y1 - label_size[1] - 10\n",
    "                    label_x2, label_y2 = x1 + label_size[0] + 10, y1\n",
    "                    cv2.rectangle(frame, (label_x1, label_y1), (label_x2, label_y2), color, -1)\n",
    "                    cv2.putText(frame, label, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "                cv2.imshow(window_title, frame)\n",
    "                \n",
    "                keyCode = cv2.waitKey(10) & 0xFF\n",
    "                # Stop the program on the ESC key or 'q'\n",
    "                if keyCode == 27 or keyCode == ord('q'):\n",
    "                    break\n",
    "        finally:\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Error: Unable to open camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ce512-3dbb-467c-9ab6-970bcf69d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prune(model, amount=0.3):\n",
    "    import torch.nn.utils.prune as prune\n",
    "    print('Pruning model... ', end='')\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(m, name='weight', amount=amount)  # prune\n",
    "            prune.remove(m, 'weight')  # make permanent\n",
    "    print(' %.3g global sparsity' % sparsity(model))\n",
    "            \n",
    "def sparsity(model):\n",
    "    # Return global model sparsity\n",
    "    a, b = 0, 0\n",
    "    for p in model.parameters():\n",
    "        a += p.numel()\n",
    "        b += (p == 0).sum()\n",
    "    return b / a\n",
    "\n",
    "def quantize(model):\n",
    "    from torch.quantization import quantize_dynamic\n",
    "    quantized_model = quantize_dynamic(model, qconfig_spec={torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "    #print(quantized_model)\n",
    "    return quantized_model\n",
    "\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1107ce-dacb-4e77-8e84-187fa180c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b9607-6315-49cb-90b5-498412c189f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf766168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('/home/jetson/yolov5', 'custom', 'weights/best.pt', source='local', force_reload=True, device=device)\n",
    "#model = torch.hub.load('ultralytics/yolov5', \"custom\", \"models/best.pt\", force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune(model, amount=0.3)\n",
    "model = quantize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fdc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
